import requests
from bs4 import BeautifulSoup

def check_server_version(headers):
    server_header = headers.get('Server', '')
    if server_header:
        print(f"Server header found: {server_header}")
        # You can expand this part to check for known vulnerable versions
    else:
        print("No Server header found.")

def check_directory_listing(url):
    try:
        response = requests.get(url + "/test/")
        if response.status_code == 200 and "Index of /" in response.text:
            print("Directory listing is enabled!")
        else:
            print("Directory listing is not enabled.")
    except requests.exceptions.RequestException as e:
        print(f"Error checking directory listing: {e}")

def check_js_libraries(html_content):
    soup = BeautifulSoup(html_content, 'html.parser')
    scripts = soup.find_all('script', src=True)
    for script in scripts:
        src = script['src']
        if "jquery" in src.lower():
            print(f"Found jQuery library: {src}")
           

def scan_website(url):
    try:
        response = requests.get(url)
        response.raise_for_status()
        print(f"Scanning {url}...")
        check_server_version(response.headers)
        check_directory_listing(url)
        check_js_libraries(response.text)
    except requests.exceptions.RequestException as e:
        print(f"Error scanning {url}: {e}")

if __name__ == "__main__":
    target_url = input("Enter the URL to scan: ")
    scan_website(target_url)

